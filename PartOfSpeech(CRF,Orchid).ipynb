{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PartOfSpeech(CRF,Orchid).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5ry/s2w23aVgS+Us/jZgV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/defyMiy/Intern/blob/main/PartOfSpeech(CRF%2COrchid).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8T1l2q_mA4k",
        "outputId": "1e9f79a7-dcad-48d5-dc6b-657aa1a1563c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul  4 14:31:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "!wget https://raw.githubusercontent.com/tchayintr/thtb/master/thtb_orchidpp.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdTMtdONwxb6",
        "outputId": "6d8c0182-1421-47c8-cfde-aac6150650bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-04 14:31:24--  https://raw.githubusercontent.com/tchayintr/thtb/master/thtb_orchidpp.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2064161 (2.0M) [text/plain]\n",
            "Saving to: ‘thtb_orchidpp.txt’\n",
            "\n",
            "thtb_orchidpp.txt   100%[===================>]   1.97M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-07-04 14:31:24 (46.7 MB/s) - ‘thtb_orchidpp.txt’ saved [2064161/2064161]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn_crfsuite\n",
        "!pip install scikit-learn==0.22.2\n",
        "!pip install nltk pythainlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuoxbf_ns4ks",
        "outputId": "da76a886-5fcf-4cde-c0d5-1c8140f39333"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.8 sklearn-crfsuite-0.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==0.22.2\n",
            "  Downloading scikit_learn-0.22.2-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.21.6)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.22.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Collecting pythainlp\n",
            "  Downloading pythainlp-3.0.8-py3-none-any.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n",
            "Collecting tinydb>=3.0\n",
            "  Downloading tinydb-4.7.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp) (4.1.1)\n",
            "Installing collected packages: tinydb, pythainlp\n",
            "Successfully installed pythainlp-3.0.8 tinydb-4.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pythainlp.github.io/dev-docs/api/tag.html\n",
        "POS_TAG = {\n",
        "    'NOUN' : ['NOUN', 'NCMN', 'NTTL', 'CNIT', 'CLTV', 'CMTR', 'CFQC', 'CVBL'],\n",
        "    'VERB' : ['VACT', 'VSTA'],\n",
        "    'PROPN' : ['PROPN', 'NPRP'],\n",
        "    'ADJ' : ['ADJ', 'NONM', 'VATT', 'DONM'],\n",
        "    'ADV' : ['ADV', 'ADVN', 'ADVI', 'ADVP', 'ADVS'],\n",
        "    'INTJ' : ['INT'],\n",
        "    'PRON' : ['PRON', 'PPRS', 'PDMN', 'PNTR'],\n",
        "    'DET' : ['DET', 'DDAN', 'DDAC', 'DDBQ', 'DDAQ', 'DIAC', 'DIBQ', 'DIAQ'],\n",
        "    'NUM' : ['NUM', 'NCNM', 'NLBL', 'DCNM'],\n",
        "    'AUX' : ['AUX', 'XVBM', 'XVAM', 'XVMM', 'XVBB', 'XVAE'],\n",
        "    'ADP' : ['ADP', 'RPRE'],\n",
        "    'CCONJ' : ['CCONJ', 'JCRG'],\n",
        "    'SCONJ' : ['SCONJ', 'PREL', 'JSBR', 'JCMP'],\n",
        "    'PART' : ['PART', 'FIXN', 'FIXV', 'EAFF', 'EITT', 'NEG'],\n",
        "    'PUNCT' : ['PUNCT', 'PUNC']\n",
        "}"
      ],
      "metadata": {
        "id": "gM_kYfDCVgcJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('thtb_orchidpp.txt', 'r') as f:\n",
        "  sentences = f.read().split('\\n')\n",
        "  f.close()\n",
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAxnOhQwMGpB",
        "outputId": "474b8dcd-302a-4b2d-c5e6-6044dbf1460d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5001"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from IPython.display import clear_output\n",
        "\n",
        "tagged_sentence = []\n",
        "\n",
        "for num, sentence in enumerate(sentences):\n",
        "  print('{:.2f}'.format(num * 100 / len(sentences)))\n",
        "  tag_words = []\n",
        "  words = sentence.split(' ')\n",
        "  for i, word in enumerate(words):\n",
        "    for key in POS_TAG:\n",
        "      for value in POS_TAG.get(key):\n",
        "        if '[' + value in word:\n",
        "          if ']' not in words[i+1]:\n",
        "            tag_word = (words[i+1] + ' ' + words[i+2].replace(']', ''), key)\n",
        "          else:\n",
        "            tag_word = (words[i+1].replace(']', ''), key)\n",
        "          tag_words.append(tag_word)\n",
        "  tagged_sentence.append(tag_words)\n",
        "  clear_output()\n",
        "print(\"Number of Tagged Sentences \", len(tagged_sentence))\n",
        "\n",
        "tagged_words = [tup for sent in tagged_sentence for tup in sent]\n",
        "print(\"Total Number of Tagged words\", len(tagged_words))\n",
        "\n",
        "vocab = set([word for word,tag in tagged_words])\n",
        "print(\"Vocabulary of the Corpus\", len(vocab))\n",
        "\n",
        "tags = set([tag for word,tag in tagged_words])\n",
        "print(\"Number of Tags in the Corpus \", len(tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeH55j59XFJk",
        "outputId": "7623ccce-1665-4b1c-f2c3-a3272177a7b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Tagged Sentences  5001\n",
            "Total Number of Tagged words 86046\n",
            "Vocabulary of the Corpus 6152\n",
            "Number of Tags in the Corpus  14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(tagged_sentence,test_size=0.2,random_state=1234)\n",
        "print(\"Number of Sentences in Training Data \",len(train_set))\n",
        "print(\"Number of Sentences in Testing Data \",len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7KzC1JStY16",
        "outputId": "675a600f-7c94-49a4-ef75-614be870766e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Sentences in Training Data  4000\n",
            "Number of Sentences in Testing Data  1001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def features(sentence,index):\n",
        "    ### sentence is of the form [w1,w2,w3,..], index is the position of the word in the sentence\n",
        "    return {\n",
        "        'is_first_capital':int(sentence[index][0].isupper()),\n",
        "        'is_first_word': int(index==0),\n",
        "        'is_last_word':int(index==len(sentence)-1),\n",
        "        'is_complete_capital': int(sentence[index].upper()==sentence[index]),\n",
        "        'prev_word':'' if index==0 else sentence[index-1],\n",
        "        'next_word':'' if index==len(sentence)-1 else sentence[index+1],\n",
        "        'is_numeric':int(sentence[index].isdigit()),\n",
        "        'is_alphanumeric': int(bool((re.match('^(?=.*[0-9]$)(?=.*[a-zA-Z])',sentence[index])))),\n",
        "        'prefix_1':sentence[index][0],\n",
        "        'prefix_2': sentence[index][:2],\n",
        "        'prefix_3':sentence[index][:3],\n",
        "        'prefix_4':sentence[index][:4],\n",
        "        'suffix_1':sentence[index][-1],\n",
        "        'suffix_2':sentence[index][-2:],\n",
        "        'suffix_3':sentence[index][-3:],\n",
        "        'suffix_4':sentence[index][-4:],\n",
        "        'word_has_hyphen': 1 if '-' in sentence[index] else 0  \n",
        "         }\n",
        "def untag(sentence):\n",
        "    return [word for word,tag in sentence]\n",
        "\n",
        "\n",
        "def prepareData(tagged_sentences):\n",
        "    X,y=[],[]\n",
        "    for sentences in tagged_sentences:\n",
        "        X.append([features(untag(sentences), index) for index in range(len(sentences))])\n",
        "        y.append([tag for word,tag in sentences])\n",
        "    return X,y\n",
        "X_train,y_train=prepareData(train_set)\n",
        "X_test,y_test=prepareData(test_set)"
      ],
      "metadata": {
        "id": "dwzf8g-BuAl6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_crfsuite import CRF\n",
        "\n",
        "crf = CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.01,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHazA5KzuOh5",
        "outputId": "f7182bb8-2c9b-4c23-bfdc-4f39861f1951"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.01, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_crfsuite import metrics\n",
        "from sklearn_crfsuite import scorers\n",
        "\n",
        "y_pred=crf.predict(X_test)\n",
        "print(\"F1 score on Test Data \")\n",
        "print(metrics.flat_f1_score(y_test, y_pred,average='weighted',labels=crf.classes_))\n",
        "print(\"F score on Training Data \")\n",
        "y_pred_train=crf.predict(X_train)\n",
        "metrics.flat_f1_score(y_train, y_pred_train,average='weighted',labels=crf.classes_)\n",
        "\n",
        "### Look at class wise score\n",
        "print(metrics.flat_classification_report(\n",
        "    y_test, y_pred, labels=crf.classes_, digits=3\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YUTOXI-wZ1P",
        "outputId": "0c345979-277f-4eff-9c62-ceeab50de627"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score on Test Data \n",
            "0.9208074642392937\n",
            "F score on Training Data \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        PART      0.948     0.876     0.910       893\n",
            "        VERB      0.922     0.916     0.919      2814\n",
            "         DET      0.941     0.947     0.944       304\n",
            "         ADP      0.893     0.900     0.896      1476\n",
            "        NOUN      0.925     0.923     0.924      4977\n",
            "         ADV      0.936     0.952     0.944       690\n",
            "       PROPN      0.895     0.798     0.844       193\n",
            "       CCONJ      0.867     0.860     0.863       242\n",
            "       SCONJ      0.872     0.865     0.869       772\n",
            "         AUX      0.896     0.927     0.911       765\n",
            "         NUM      0.903     0.888     0.895       365\n",
            "        PRON      0.908     0.908     0.908        65\n",
            "         ADJ      0.964     0.960     0.962       845\n",
            "       PUNCT      0.930     0.959     0.944      2624\n",
            "\n",
            "    accuracy                          0.921     17025\n",
            "   macro avg      0.914     0.906     0.910     17025\n",
            "weighted avg      0.921     0.921     0.921     17025\n",
            "\n"
          ]
        }
      ]
    }
  ]
}